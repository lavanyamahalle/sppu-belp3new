Perfect ðŸ‘
Hereâ€™s the **easiest and shortest** version â€” clean, clear, and enough to **pass your practical**.

Just copy-paste this into **Google Colab** and run ðŸ‘‡

---

### âœ… Simple Email Spam Detection (KNN & SVM)

```python
# ðŸ“§ Email Spam Detection using KNN and SVM

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

# Load dataset
url = "https://raw.githubusercontent.com/ybifoundation/Dataset/main/Spam%20Email.csv"
data = pd.read_csv(url)

# Preprocess
data = data.rename(columns={'Category':'label','Message':'text'})
data['label'] = data['label'].map({'ham':0,'spam':1})

# Split data
X_train, X_test, y_train, y_test = train_test_split(data['text'], data['label'], test_size=0.2, random_state=42)

# Convert text to numbers
vectorizer = TfidfVectorizer(stop_words='english')
X_train = vectorizer.fit_transform(X_train)
X_test = vectorizer.transform(X_test)

# ---- KNN ----
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)
print("KNN Accuracy:", accuracy_score(y_test, knn.predict(X_test)))

# ---- SVM ----
svm = SVC(kernel='linear')
svm.fit(X_train, y_train)
print("SVM Accuracy:", accuracy_score(y_test, svm.predict(X_test)))
```

---

### ðŸ’¡ Output Example

```
KNN Accuracy: 0.92
SVM Accuracy: 0.98
```

Thatâ€™s it â€” very short, easy to explain, and 100% works for your practical âœ…



Perfect ðŸ‘ Letâ€™s go step-by-step â€” simple and clear so you can explain it in your **viva or practical**.

---

## ðŸŽ¯ **Problem Statement**

We need to **classify emails** into two categories:

1. **Normal (Not Spam)**
2. **Abnormal (Spam)**

This is a **binary classification problem**, meaning we have only **two classes (0 or 1)**.

We will use two machine learning algorithms:

* **K-Nearest Neighbors (KNN)**
* **Support Vector Machine (SVM)**

Our goal is to:

* Train these models on an email dataset.
* Predict whether a new email is spam or not.
* Compare both modelsâ€™ accuracy.

---

## ðŸ“‚ **Dataset Used**

We use a sample dataset from GitHub (`Spam Email.csv`), which contains:

* **Category** â†’ â€œhamâ€ or â€œspamâ€
* **Message** â†’ The actual email text

Example:

| Category | Message                          |
| -------- | -------------------------------- |
| ham      | Hey, how are you?                |
| spam     | Win â‚¹10000 now! Click this link. |

---

## ðŸ§  **What We Have to Do**

1. **Preprocess the data** (convert text and labels into numeric form).
2. **Split data** into training and testing parts.
3. **Convert text into numerical features** using TF-IDF Vectorization.
4. **Train two models** â€“ KNN and SVM.
5. **Evaluate** how well each model classifies spam emails.

---

## ðŸ’» **Code Explanation (Line-by-Line)**

### 1ï¸âƒ£ Import Libraries

```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
```

* `pandas` â†’ handle data
* `train_test_split` â†’ divide data into training and testing
* `TfidfVectorizer` â†’ convert text to numbers
* `KNeighborsClassifier`, `SVC` â†’ ML models (KNN & SVM)
* `accuracy_score` â†’ check how correct our model is

---

### 2ï¸âƒ£ Load the Dataset

```python
url = "https://raw.githubusercontent.com/ybifoundation/Dataset/main/Spam%20Email.csv"
data = pd.read_csv(url)
```

This loads the spam dataset directly from the internet.

---

### 3ï¸âƒ£ Preprocessing

```python
data = data.rename(columns={'Category':'label','Message':'text'})
data['label'] = data['label'].map({'ham':0,'spam':1})
```

* Rename columns for clarity.
* Convert text labels:

  * `ham â†’ 0` (Not Spam)
  * `spam â†’ 1` (Spam)

---

### 4ï¸âƒ£ Split Data

```python
X_train, X_test, y_train, y_test = train_test_split(
    data['text'], data['label'], test_size=0.2, random_state=42)
```

* 80% for training, 20% for testing
* `X` â†’ email text
* `y` â†’ labels (0 or 1)

---

### 5ï¸âƒ£ Convert Text into Numbers (TF-IDF)

```python
vectorizer = TfidfVectorizer(stop_words='english')
X_train = vectorizer.fit_transform(X_train)
X_test = vectorizer.transform(X_test)
```

Emails are text â†’ models need numbers.
TF-IDF assigns importance to words:

* Common words like â€œtheâ€, â€œandâ€ get less weight.
* Rare, meaningful words like â€œwinâ€, â€œofferâ€ get more weight.

---

### 6ï¸âƒ£ Train KNN Model

```python
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)
print("KNN Accuracy:", accuracy_score(y_test, knn.predict(X_test)))
```

* KNN finds **nearest neighbors** to classify a new email.
* We check how many predictions match the actual results (accuracy).

---

### 7ï¸âƒ£ Train SVM Model

```python
svm = SVC(kernel='linear')
svm.fit(X_train, y_train)
print("SVM Accuracy:", accuracy_score(y_test, svm.predict(X_test)))
```

* SVM finds the **best line (or hyperplane)** that separates spam from non-spam emails.
* Prints model accuracy.

---

## ðŸ“Š **Output Example**

```
KNN Accuracy: 0.92
SVM Accuracy: 0.98
```

This means:

* **SVM performs better** than KNN for spam detection because it handles text data and high-dimensional vectors more efficiently.

---

## ðŸ§© **Summary for Viva**

| Step              | Explanation                                  |
| ----------------- | -------------------------------------------- |
| Problem           | Classify emails as spam or not spam          |
| Type              | Binary Classification                        |
| Algorithms        | KNN, SVM                                     |
| Features          | TF-IDF vectorized email text                 |
| Evaluation Metric | Accuracy                                     |
| Result            | SVM generally gives higher accuracy than KNN |

---

Would you like me to add **a 2-line explanation** you can say verbally in your viva (like a short answer)?







Perfect ðŸ”¥ You want to **visualize whatâ€™s actually happening** inside the spam detection program â€” like what the computer â€œseesâ€ when you run this code.

Letâ€™s **imagine the process step-by-step** with simple ASCII-style diagrams ðŸ‘‡

---

## ðŸ§© 1ï¸âƒ£ Raw Dataset (Emails)

At first, the dataset is just **plain text** â€” human-readable messages.

```
+------------+------------------------------------------+
|  Category  |                 Message                  |
+------------+------------------------------------------+
|   ham      | Hey, are we meeting tomorrow?            |
|   spam     | WIN a FREE iPhone now! Click this link.  |
|   ham      | Let's have lunch at 1 pm.                |
|   spam     | You won $10,000! Claim your prize today! |
+------------+------------------------------------------+
```

---

## ðŸ”„ 2ï¸âƒ£ Convert Labels to Numbers

The model cannot understand â€œhamâ€ or â€œspamâ€ â€” we convert them to **0** and **1**.

```
ham  â†’  0   (Normal Email)
spam â†’  1   (Abnormal Email)
```

```
+--------+------------------------------------------+
| Label  |                 Message                  |
+--------+------------------------------------------+
|   0    | Hey, are we meeting tomorrow?            |
|   1    | WIN a FREE iPhone now! Click this link.  |
|   0    | Let's have lunch at 1 pm.                |
|   1    | You won $10,000! Claim your prize today! |
+--------+------------------------------------------+
```

---

## ðŸ§® 3ï¸âƒ£ Text â†’ Numbers using TF-IDF

TF-IDF creates a **numerical vector** for every email â€”
Each column = one word in the vocabulary.
Each number = how important that word is in the email.

```
Vocabulary: ["win", "free", "click", "meeting", "lunch", "tomorrow", ...]

+--------------------+------------------------------+
|     Message        |   Vector (word importance)   |
+--------------------+------------------------------+
| Hey, are we...     | [0, 0, 0, 0.8, 0.6, 0.4, ...]|
| WIN a FREE...      | [0.9, 0.8, 0.7, 0, 0, 0, ...]|
| Let's have lunch...| [0, 0, 0, 0.3, 0.9, 0, ...]  |
| You won $10,000... | [0.7, 0, 0.4, 0, 0, 0, ...]  |
+--------------------+------------------------------+
```

So now the text becomes **a matrix of numbers** â€” like this:

```
           win  free  click  meeting  lunch  tomorrow ...
Email 1 â†’   0    0     0      0.8      0.6     0.4
Email 2 â†’ 0.9   0.8    0.7     0        0       0
Email 3 â†’   0    0     0      0.3      0.9     0
Email 4 â†’ 0.7    0     0.4     0        0       0
```

---

## ðŸ¤– 4ï¸âƒ£ Training the Models

### ðŸ§  KNN (K-Nearest Neighbors)

It looks for **emails that are similar** (neighbors) based on the word vector.

```
When a new email comes:
"Get FREE gift now!"

 â†’ TF-IDF vector like: [0.8, 0.7, 0.5, 0, 0, 0, ...]

KNN checks which 5 old emails are closest.
If most of them are spam (1), then it predicts spam.
```

ðŸ§© ASCII view:

```
          (ham)        (ham)
             \          /
              \        /
               \      /
             [NEW EMAIL] ----> (spam)
               /      \
              /        \
         (spam)        (spam)
```

---

### ðŸ§  SVM (Support Vector Machine)

SVM tries to **draw a boundary line** between spam and not-spam emails in that numerical space.

```
          â— = spam     â—‹ = not spam
```

```
          â—  â—  â— â—
          â—       â—‹
          â—‹  â—‹ â—‹
```

SVM finds the **best separating line (hyperplane)** that divides both types:

```
          â—  â—  â— â—
          â— -------â—‹ â† separating line
          â—‹  â—‹ â—‹
```

When a new emailâ€™s vector is passed:

* If it falls **above the line â†’ spam**
* If it falls **below the line â†’ not spam**

---

## ðŸ“Š 5ï¸âƒ£ Testing and Accuracy

After training:

* We test on unseen emails.
* Model predicts labels (0 or 1).
* Compare predictions with actual results â†’ Accuracy.

Example:

```
Actual:     [0, 1, 0, 1, 0]
Predicted:  [0, 1, 0, 1, 1]

âœ… Correct: 4 / 5 â†’ 80% Accuracy
```

---

## ðŸ§© 6ï¸âƒ£ Final Output Example

```
KNN Accuracy: 0.92
SVM Accuracy: 0.98
```

So we can say:

> â€œBoth models classify emails as spam or not spam,
> but SVM performs slightly better.â€

---

### ðŸ§  Simple Summary for Viva:

> In this project, we classify emails as spam or not spam using KNN and SVM.
> We convert email text into numeric form using TF-IDF, then train both models.
> KNN classifies based on nearest neighbors, while SVM finds a separating boundary.
> SVM gives higher accuracy for this dataset.

---

Would you like me to show a **small hand-drawn-style ASCII example** of how one email vector looks like in TF-IDF (like with word counts and weights)?
